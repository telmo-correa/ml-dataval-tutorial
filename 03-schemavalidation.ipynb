{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f02f268e-8546-40fa-968b-8644f5b3ff0f",
   "metadata": {
    "tags": []
   },
   "source": [
    "![](https://raw.githubusercontent.com/wandb/wandb/508982e50e82c54cbf0dd464a9959fee0e1740ad/.github/wb-logo-lightbg.png)\n",
    "<!--- @wandbcode{dataval-course-03} -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521fc8bf-0cd0-45d2-8ba0-fe8a84d588c4",
   "metadata": {},
   "source": [
    "# Schema Validation\n",
    "\n",
    "In this notebook, we will implement TFX's schema validation to see if any of the corruptions in the previous notebook were detected. We'll log the results of schema validation to wandb.\n",
    "\n",
    "You can set up wandb alerts here: https://docs.wandb.ai/guides/runs/alert\n",
    "\n",
    "I use Modal because TFDV doesn't run on Mac M1s. You can create a free account on Modal here: https://modal.com/signup -- it comes with $10/month credits, which should be plenty more than enough to run the notebooks in this course. Once you have created an account, follow the \"Getting Started\" instructions on the homepage:\n",
    "\n",
    "* Run `pip install modal-client` (also included in `requirements.txt` in this repo)\n",
    "* Run `modal token new`, which will open a browser window and authenticate you with your account\n",
    "\n",
    "Then you should be able to run this notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1ea6f8-9f74-4293-8eba-fd54c99e9b41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dataval.dataset import WeatherDataset\n",
    "from dataval.train import CatBoostTrainer\n",
    "from dataval import dataset_extensions\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import modal\n",
    "import pandas as pd\n",
    "\n",
    "import wandb\n",
    "from wandb import AlertLevel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3224acec-34e7-4f82-a0d4-50346a27f6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = (\n",
    "    modal.Image.debian_slim()\n",
    "    .pip_install_from_requirements(\"requirements.txt\")\n",
    "    .pip_install([\"tensorflow-data-validation\", \"tensorflow_metadata\", \"protobuf==3.20.0\"])\n",
    ")\n",
    "stub = modal.Stub(\"tfdv-tutorial\", image=image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3617e8db-23f1-462e-9b28-5f6a2c166005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "\n",
    "ds = WeatherDataset(os.path.join(os.getcwd(), \"canonical-paritioned-dataset\"), sample_frac=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee990491-48e1-4b54-8091-2d5525ad13a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = ds.load(ds.get_partition_keys()[0])\n",
    "test_df = ds.load(ds.get_partition_keys()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41df963a-cb49-453b-92ea-3fdb7669c8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd13aa8-ff64-461b-a140-a458b5ce476d",
   "metadata": {},
   "source": [
    "## Infer schema and check test data for errors\n",
    "\n",
    "From the train dataframe, we create a schema using TFDV. Then we use this schema to find anomalies in the test data. We apply this to the original dataframes first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e447e88-19ea-458f-9ee8-5ff26eb23425",
   "metadata": {},
   "outputs": [],
   "source": [
    "@stub.function()\n",
    "def find_anomalies(train_df, test_df):\n",
    "    import tensorflow_data_validation as tfdv\n",
    "    from google.protobuf.json_format import MessageToDict\n",
    "    \n",
    "    train_stats =  tfdv.generate_statistics_from_dataframe(train_df)\n",
    "    schema = tfdv.infer_schema(statistics=train_stats)\n",
    "    test_stats = tfdv.generate_statistics_from_dataframe(test_df)\n",
    "    \n",
    "    anomalies = tfdv.validate_statistics(statistics=test_stats, schema=schema)\n",
    "    anomalies_df = tfdv.utils.display_util.get_anomalies_dataframe(anomalies)\n",
    "    # return MessageToDict(anomalies)\n",
    "    return anomalies_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b52dd3-9d48-4597-ad44-62d31166b4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with stub.run():\n",
    "    X_train, _ = ds.split_feature_label(train_df)\n",
    "    X_test, _ = ds.split_feature_label(test_df)\n",
    "    anomalies = find_anomalies.call(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b79957-7699-4719-bb94-4f9fe71c8880",
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ab0865-2794-45a4-b0fd-551f64c8d2e4",
   "metadata": {},
   "source": [
    "Seems like the raw data did not have any anomalies!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7686fd3-4aa3-4cce-b7e7-b9e356ef39cf",
   "metadata": {},
   "source": [
    "## Iterate through corruptions\n",
    "\n",
    "See if tfdv detects any anomalies, for all the corruptions we had in our previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a73c2a1-39db-4f38-b742-0a642a7b3408",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, _ = ds.split_feature_label(train_df)\n",
    "corruption_anomalies = {}\n",
    "\n",
    "for corruption_name, corruption_res in ds.iterate_corruptions_by_feature(test_df, \"cmc\", corruption_rate=0.05):\n",
    "    corrupted_test_df, corrupted_columns = corruption_res\n",
    "    corrupted_X_test, _ = ds.split_feature_label(corrupted_test_df)\n",
    "    with stub.run():\n",
    "        corruption_anomalies[corruption_name] = find_anomalies.call(X_train, corrupted_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec058da3-b1aa-4ace-abfd-c1df19f19a1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Send wandb alerts\n",
    "\n",
    "run = wandb.init(project=\"ml-dataval-tutorial\", tags=[\"TFDV-schema\"])\n",
    "\n",
    "for corruption_name, anomalies in corruption_anomalies.items():\n",
    "    if len(anomalies) > 0:\n",
    "        table = wandb.Table(dataframe=anomalies)\n",
    "        wandb.log({corruption_name: table})\n",
    "    \n",
    "        wandb.alert(\n",
    "            title=f\"Errors detected in {corruption_name} experiment\", \n",
    "            text = f\"Found {len(anomalies)} anomalies\",\n",
    "            level=AlertLevel.WARN,\n",
    "        )\n",
    "        print(f\"Found {len(anomalies)} in {corruption_name} experiment\")\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367e9ee8-ad93-42bc-8765-9947b2cdfbb0",
   "metadata": {},
   "source": [
    "## Takeaways\n",
    "\n",
    "It looks like only the `corrupt_null` corruption was flagged by schema validation! Maybe other validation techniques might flag them. Nevertheless, all the corruptions that schema validation found were true corruptions, so there isn't a false positive alert problem here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f746c5e-97f0-46fc-a0e1-f1811496d645",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
