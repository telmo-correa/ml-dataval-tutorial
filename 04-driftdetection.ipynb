{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f68fd4b3-63bb-435e-a211-f59bf6ac2f80",
   "metadata": {},
   "source": [
    "![](https://raw.githubusercontent.com/wandb/wandb/508982e50e82c54cbf0dd464a9959fee0e1740ad/.github/wb-logo-lightbg.png)\n",
    "<!--- @wandbcode{dataval-course-04} -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be16292-e3d0-4aa5-998d-7c0324faaa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataval.dataset import WeatherDataset\n",
    "from dataval.train import CatBoostTrainer\n",
    "from dataval import dataset_extensions\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import modal\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f8c931-960e-4448-bff1-16286d2f189c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = (\n",
    "    modal.Image.debian_slim()\n",
    "    .pip_install_from_requirements(\"requirements.txt\")\n",
    "    .pip_install([\"tensorflow-data-validation\", \"tensorflow_metadata\", \"protobuf==3.20.0\"])\n",
    ")\n",
    "stub = modal.Stub(\"tfdv-tutorial\", image=image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef80411-6751-402e-9f03-5085d6c0208c",
   "metadata": {},
   "source": [
    "# Drift Detection\n",
    "\n",
    "Schema validation catches some, but not all, corruptions. In this notebook, we leverage TFDV's drift detection tool to see if all corruptions are identified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617f7fb3-bb8f-4258-8f2f-77298cc42ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "\n",
    "ds = WeatherDataset(os.path.join(os.getcwd(), \"canonical-paritioned-dataset\"), sample_frac=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49374ace-9e92-4992-8da4-cdc1a29beb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = ds.load(ds.get_partition_keys()[0])\n",
    "test_df = ds.load(ds.get_partition_keys()[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1a5b07-2c50-4134-a39e-e793a26ef42f",
   "metadata": {},
   "source": [
    "## Check for skew between train and test partitions\n",
    "\n",
    "We use TFDV to infer the schema of the train partition and then check the test partition for skew. TFDV checks for distribution shift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfe505f-589c-46d6-8b8a-6ab56b68fb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "@stub.function()\n",
    "def check_skew(train_df, test_df, feature_columns):\n",
    "    import tensorflow_data_validation as tfdv\n",
    "    from google.protobuf.json_format import MessageToDict\n",
    "    \n",
    "    train_stats =  tfdv.generate_statistics_from_dataframe(train_df)\n",
    "    schema = tfdv.infer_schema(statistics=train_stats)\n",
    "    test_stats = tfdv.generate_statistics_from_dataframe(test_df)\n",
    "    \n",
    "    for feature in feature_columns:\n",
    "        tfdv.get_feature(schema, feature).skew_comparator.jensen_shannon_divergence.threshold = 0.1\n",
    "\n",
    "    skew_anomalies = tfdv.validate_statistics(statistics=train_stats, schema=schema, serving_statistics=test_stats)\n",
    "    anomalies_df = tfdv.utils.display_util.get_anomalies_dataframe(skew_anomalies)\n",
    "\n",
    "    return anomalies_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b039d0-7068-4f36-ad43-3e29b6eb0389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run on regular train and test data\n",
    "\n",
    "with stub.run():\n",
    "    X_train, _ = ds.split_feature_label(train_df)\n",
    "    X_test, _ = ds.split_feature_label(test_df)\n",
    "    anomalies = check_skew.call(X_train, X_test, X_train.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc98700-03ec-4523-88e0-f0ca142a4474",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 100\n",
    "anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fad42b-ab0e-4f9d-8984-ac6ebce16581",
   "metadata": {},
   "source": [
    "Wow, it looks like there were many alerts triggered! Unclear if these alerts are meaningful though, as the test performance is not so much worse than the train performance. Also, how would we interpret the alerts?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2449bf1-355c-4bc8-9722-fec64c6c6f99",
   "metadata": {},
   "source": [
    "## Iterate through corruptions\n",
    "\n",
    "See if tfdv detects any anomalies, for all the corruptions we had in our previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0445a42f-b3b7-4fd6-99aa-1a51123b717b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, _ = ds.split_feature_label(train_df)\n",
    "corruption_anomalies = {}\n",
    "corruption_columns = {}\n",
    "\n",
    "with stub.run():\n",
    "    for corruption_name, corruption_res in ds.iterate_corruptions_by_feature(test_df, \"cmc\", corruption_rate=0.05):\n",
    "        corrupted_test_df, corrupted_columns = corruption_res\n",
    "        corrupted_X_test, _ = ds.split_feature_label(corrupted_test_df)\n",
    "        corruption_anomalies[corruption_name] = check_skew.call(X_train, corrupted_X_test, X_train.columns.values)\n",
    "        corruption_columns[corruption_name] = corrupted_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca54760-5628-465c-a0fa-b58c67c51e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send wandb alerts\n",
    "import wandb\n",
    "from wandb import AlertLevel\n",
    "\n",
    "run = wandb.init(project=\"ml-dataval-tutorial\", tags=[\"TFDV-drift\"])\n",
    "\n",
    "metrics = []\n",
    "\n",
    "for corruption_name, anomalies in corruption_anomalies.items():\n",
    "    \n",
    "    if len(anomalies) > 0:\n",
    "        table = wandb.Table(dataframe=anomalies)\n",
    "        wandb.log({corruption_name: table})\n",
    "    \n",
    "        found_columns = [a[1:-1] for a in anomalies.index.values]\n",
    "        inter = set(found_columns).intersection(set(corruption_columns[corruption_name]))\n",
    "        \n",
    "        wandb.alert(\n",
    "            title=f\"Errors detected in {corruption_name} experiment\", \n",
    "            text = f\"TFDV found {len(inter)} of {len(corruption_columns[corruption_name])} anomalies for corruption {corruption_name}. TFDV flagged {len(set(found_columns))} in total.\",\n",
    "            level=AlertLevel.WARN,\n",
    "        )\n",
    "        print(f\"TFDV found {len(anomalies)} anomalies in {corruption_name} experiment\")\n",
    "        \n",
    "        precision = float(len(inter) / len(set(found_columns)))\n",
    "        recall = float(len(inter) / len(corruption_columns[corruption_name]))\n",
    "        metrics.append({\"corruption_name\": corruption_name, \"precision\": precision, \"recall\": recall})\n",
    "    \n",
    "# Log precision and recall\n",
    "metric_df = pd.DataFrame(metrics)\n",
    "metric_table = wandb.Table(dataframe=metric_df)\n",
    "wandb.log({\"precision\" : wandb.plot.bar(metric_table, \"corruption_name\", \"precision\",\n",
    "           title=\"Precision\")})\n",
    "wandb.log({\"recall\" : wandb.plot.bar(metric_table, \"corruption_name\", \"recall\",\n",
    "           title=\"Recall\")})\n",
    "# wandb.log({\"metrics\": metric_table})\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0f540c-84b9-4ca9-a685-6faf87c324b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af9638f-f269-493e-93c4-aec7ea1a43f3",
   "metadata": {},
   "source": [
    "## Takeaways\n",
    "\n",
    "Looks like TFDV didn't find all the right anomalies, but it found nonzero! Finding alerts precisely is very hard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af41945f-5234-43e6-a6a3-ecd04d7f1d11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
